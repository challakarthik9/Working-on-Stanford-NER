{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Version:3.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"NLTK Version:%s\" %nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Could not find stanford-ner.jar jar file at stanford_ner/stanford-ner-3.9.2.jar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-cce01aed48a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m stanford_ner_tagger = StanfordNERTagger(\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m'stanford_ner/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'classifiers/english.muc.7class.distsim.crf.ser.gz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m'stanford_ner/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'stanford-ner-3.9.2.jar'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStanfordNERTagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m             )\n\u001b[0;32m     73\u001b[0m         self._stanford_jar = find_jar(\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_stanford_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_jar\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    852\u001b[0m     return next(\n\u001b[0;32m    853\u001b[0m         find_jar_iter(\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mname_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_regex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m         )\n\u001b[0;32m    856\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             raise LookupError(\n\u001b[1;32m--> 740\u001b[1;33m                 \u001b[1;34m'Could not find %s jar file at %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m             )\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: Could not find stanford-ner.jar jar file at stanford_ner/stanford-ner-3.9.2.jar"
     ]
    }
   ],
   "source": [
    "stanford_ner_tagger = StanfordNERTagger(\n",
    "    'stanford_ner/' + 'classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "    'stanford_ner/' + 'stanford-ner-3.9.2.jar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ebf83f5ddd98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mspacy_nlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\challa karthik\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "spacy_nlp = spacy.load('en')\n",
    "document = spacy_nlp(article)\n",
    "\n",
    "print('Original Sentence: %s' % (article))\n",
    "\n",
    "for element in document.ents:\n",
    "    print('Type: %s, Value: %s' % (element.label_, element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK version: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "print('NLTK version: %s' % (nltk.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Challa Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Asian', 'JJ'),\n",
       " ('shares', 'NNS'),\n",
       " ('skidded', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('Tuesday', 'NNP'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('rout', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('tech', 'JJ'),\n",
       " ('stocks', 'NNS'),\n",
       " ('put', 'VBD'),\n",
       " ('Wall', 'NNP'),\n",
       " ('Street', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('sword', 'NN'),\n",
       " (',', ','),\n",
       " ('while', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('sharp', 'JJ'),\n",
       " ('drop', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('oil', 'NN'),\n",
       " ('prices', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('political', 'JJ'),\n",
       " ('risks', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('Europe', 'NNP'),\n",
       " ('pushed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('dollar', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('16-month', 'JJ'),\n",
       " ('highs', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('investors', 'NNS'),\n",
       " ('dumped', 'VBD'),\n",
       " ('riskier', 'JJR'),\n",
       " ('assets', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('MSCI', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('broadest', 'JJS'),\n",
       " ('index', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Asia-Pacific', 'NNP'),\n",
       " ('shares', 'NNS'),\n",
       " ('outside', 'IN'),\n",
       " ('Japan', 'NNP'),\n",
       " ('dropped', 'VBD'),\n",
       " ('1.7', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('1-1/2', 'JJ'),\n",
       " ('week', 'NN'),\n",
       " ('trough', 'NN'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('Australian', 'JJ'),\n",
       " ('shares', 'NNS'),\n",
       " ('sinking', 'VBG'),\n",
       " ('1.6', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Japan', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('Nikkei', 'NNP'),\n",
       " ('dived', 'VBD'),\n",
       " ('3.1', 'CD'),\n",
       " ('percent', 'NN'),\n",
       " ('led', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('losses', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('electric', 'JJ'),\n",
       " ('machinery', 'NN'),\n",
       " ('makers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('suppliers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Apple', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('iphone', 'NN'),\n",
       " ('parts', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Sterling', 'NN'),\n",
       " ('fell', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('$', '$'),\n",
       " ('1.286', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('straight', 'JJ'),\n",
       " ('sessions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('losses', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('lowest', 'JJS'),\n",
       " ('since', 'IN'),\n",
       " ('Nov.1', 'NNP'),\n",
       " ('as', 'IN'),\n",
       " ('there', 'EX'),\n",
       " ('were', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('considerable', 'JJ'),\n",
       " ('unresolved', 'JJ'),\n",
       " ('issues', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('European', 'NNP'),\n",
       " ('Union', 'NNP'),\n",
       " ('over', 'IN'),\n",
       " ('Brexit', 'NNP'),\n",
       " (',', ','),\n",
       " ('British', 'NNP'),\n",
       " ('Prime', 'NNP'),\n",
       " ('Minister', 'NNP'),\n",
       " ('Theresa', 'NNP'),\n",
       " ('May', 'NNP'),\n",
       " ('said', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_preprocess(art):\n",
    "    art = nltk.word_tokenize(art)\n",
    "    art = nltk.pos_tag(art)\n",
    "    return art\n",
    "art_processed = fn_preprocess(article)\n",
    "art_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ne_chunk(art_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shares/NNS\n",
      "  Tuesday/NNP\n",
      "  rout/NN\n",
      "  stocks/NNS\n",
      "  (FACILITY Wall/NNP Street/NNP)\n",
      "  sword/NN\n",
      "  drop/NN\n",
      "  oil/NN\n",
      "  prices/NNS\n",
      "  risks/NNS\n",
      "  (GPE Europe/NNP)\n",
      "  dollar/NN\n",
      "  highs/NNS\n",
      "  investors/NNS\n",
      "  assets/NNS\n",
      "  (ORGANIZATION MSCI/NNP)\n",
      "  ’/NNP\n",
      "  index/NN\n",
      "  Asia-Pacific/NNP\n",
      "  shares/NNS\n",
      "  (GPE Japan/NNP)\n",
      "  percent/NN\n",
      "  week/NN\n",
      "  trough/NN\n",
      "  shares/NNS\n",
      "  percent/NN\n",
      "  (PERSON Japan/NNP)\n",
      "  ’/NNP\n",
      "  (PERSON Nikkei/NNP)\n",
      "  percent/NN\n",
      "  losses/NNS\n",
      "  machinery/NN\n",
      "  makers/NNS\n",
      "  suppliers/NNS\n",
      "  (PERSON Apple/NNP)\n",
      "  ’/NNP\n",
      "  iphone/NN\n",
      "  parts/NNS\n",
      "  (PERSON Sterling/NN)\n",
      "  sessions/NNS\n",
      "  losses/NNS\n",
      "  Nov.1/NNP\n",
      "  issues/NNS\n",
      "  (ORGANIZATION European/NNP Union/NNP)\n",
      "  (GPE Brexit/NNP)\n",
      "  (GPE British/NNP)\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  (PERSON Theresa/NNP May/NNP)\n",
      "  Monday/NNP\n"
     ]
    }
   ],
   "source": [
    "for x in str(results).split('\\n'):\n",
    "    if '/NN' in x:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iob_tagged = tree2conlltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function tree2conlltags at 0x000002AA5E779598>\n"
     ]
    }
   ],
   "source": [
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a8d587e50363>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mner\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miob_tagged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "for word, pos, ner in iob_tagged:\n",
    "    print(word, pos, ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTLK version: 3.4.1\n",
      "  shares/NNS\n",
      "  Tuesday/NNP\n",
      "  rout/NN\n",
      "  stocks/NNS\n",
      "  (FACILITY Wall/NNP Street/NNP)\n",
      "  sword/NN\n",
      "  drop/NN\n",
      "  oil/NN\n",
      "  prices/NNS\n",
      "  risks/NNS\n",
      "  (GPE Europe/NNP)\n",
      "  dollar/NN\n",
      "  highs/NNS\n",
      "  investors/NNS\n",
      "  assets/NNS\n",
      "  (ORGANIZATION MSCI/NNP)\n",
      "  ’/NNP\n",
      "  index/NN\n",
      "  Asia-Pacific/NNP\n",
      "  shares/NNS\n",
      "  (GPE Japan/NNP)\n",
      "  percent/NN\n",
      "  week/NN\n",
      "  trough/NN\n",
      "  shares/NNS\n",
      "  percent/NN\n",
      "  (PERSON Japan/NNP)\n",
      "  ’/NNP\n",
      "  (PERSON Nikkei/NNP)\n",
      "  percent/NN\n",
      "  losses/NNS\n",
      "  machinery/NN\n",
      "  makers/NNS\n",
      "  suppliers/NNS\n",
      "  (PERSON Apple/NNP)\n",
      "  ’/NNP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Challa Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Challa\n",
      "[nltk_data]     Karthik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  iphone/NN\n",
      "  parts/NNS\n",
      "  (PERSON Sterling/NN)\n",
      "  sessions/NNS\n",
      "  losses/NNS\n",
      "  Nov.1/NNP\n",
      "  issues/NNS\n",
      "  (ORGANIZATION European/NNP Union/NNP)\n",
      "  (GPE Brexit/NNP)\n",
      "  (GPE British/NNP)\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  (PERSON Theresa/NNP May/NNP)\n",
      "  Monday/NNP\n",
      "(S\n",
      "  Asian/JJ\n",
      "  shares/NNS\n",
      "  skidded/VBN\n",
      "  on/IN\n",
      "  Tuesday/NNP\n",
      "  after/IN\n",
      "  (NP a/DT rout/NN)\n",
      "  in/IN\n",
      "  tech/JJ\n",
      "  stocks/NNS\n",
      "  put/VBD\n",
      "  Wall/NNP\n",
      "  Street/NNP\n",
      "  to/TO\n",
      "  (NP the/DT sword/NN)\n",
      "  ,/,\n",
      "  while/IN\n",
      "  (NP a/DT sharp/JJ drop/NN)\n",
      "  in/IN\n",
      "  (NP oil/NN)\n",
      "  prices/NNS\n",
      "  and/CC\n",
      "  political/JJ\n",
      "  risks/NNS\n",
      "  in/IN\n",
      "  Europe/NNP\n",
      "  pushed/VBD\n",
      "  (NP the/DT dollar/NN)\n",
      "  to/TO\n",
      "  16-month/JJ\n",
      "  highs/NNS\n",
      "  as/IN\n",
      "  investors/NNS\n",
      "  dumped/VBD\n",
      "  riskier/JJR\n",
      "  assets/NNS\n",
      "  ./.\n",
      "  MSCI/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  broadest/JJS\n",
      "  (NP index/NN)\n",
      "  of/IN\n",
      "  Asia-Pacific/NNP\n",
      "  shares/NNS\n",
      "  outside/IN\n",
      "  Japan/NNP\n",
      "  dropped/VBD\n",
      "  1.7/CD\n",
      "  (NP percent/NN)\n",
      "  to/TO\n",
      "  (NP a/DT 1-1/2/JJ week/NN)\n",
      "  (NP trough/NN)\n",
      "  ,/,\n",
      "  with/IN\n",
      "  Australian/JJ\n",
      "  shares/NNS\n",
      "  sinking/VBG\n",
      "  1.6/CD\n",
      "  (NP percent/NN)\n",
      "  ./.\n",
      "  Japan/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  Nikkei/NNP\n",
      "  dived/VBD\n",
      "  3.1/CD\n",
      "  (NP percent/NN)\n",
      "  led/VBN\n",
      "  by/IN\n",
      "  losses/NNS\n",
      "  in/IN\n",
      "  (NP electric/JJ machinery/NN)\n",
      "  makers/NNS\n",
      "  and/CC\n",
      "  suppliers/NNS\n",
      "  of/IN\n",
      "  Apple/NNP\n",
      "  ’/NNP\n",
      "  s/VBD\n",
      "  (NP iphone/NN)\n",
      "  parts/NNS\n",
      "  ./.\n",
      "  (NP Sterling/NN)\n",
      "  fell/VBD\n",
      "  to/TO\n",
      "  $/$\n",
      "  1.286/CD\n",
      "  after/IN\n",
      "  three/CD\n",
      "  straight/JJ\n",
      "  sessions/NNS\n",
      "  of/IN\n",
      "  losses/NNS\n",
      "  took/VBD\n",
      "  it/PRP\n",
      "  to/TO\n",
      "  the/DT\n",
      "  lowest/JJS\n",
      "  since/IN\n",
      "  Nov.1/NNP\n",
      "  as/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  still/RB\n",
      "  considerable/JJ\n",
      "  unresolved/JJ\n",
      "  issues/NNS\n",
      "  with/IN\n",
      "  the/DT\n",
      "  European/NNP\n",
      "  Union/NNP\n",
      "  over/IN\n",
      "  Brexit/NNP\n",
      "  ,/,\n",
      "  British/NNP\n",
      "  Prime/NNP\n",
      "  Minister/NNP\n",
      "  Theresa/NNP\n",
      "  May/NNP\n",
      "  said/VBD\n",
      "  on/IN\n",
      "  Monday/NNP\n",
      "  ./.)\n",
      "[('Asian', 'JJ', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('skidded', 'VBN', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Tuesday', 'NNP', 'O'),\n",
      " ('after', 'IN', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('rout', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('tech', 'JJ', 'O'),\n",
      " ('stocks', 'NNS', 'O'),\n",
      " ('put', 'VBD', 'O'),\n",
      " ('Wall', 'NNP', 'O'),\n",
      " ('Street', 'NNP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('sword', 'NN', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('while', 'IN', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('sharp', 'JJ', 'I-NP'),\n",
      " ('drop', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('oil', 'NN', 'B-NP'),\n",
      " ('prices', 'NNS', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('political', 'JJ', 'O'),\n",
      " ('risks', 'NNS', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('Europe', 'NNP', 'O'),\n",
      " ('pushed', 'VBD', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('dollar', 'NN', 'I-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('16-month', 'JJ', 'O'),\n",
      " ('highs', 'NNS', 'O'),\n",
      " ('as', 'IN', 'O'),\n",
      " ('investors', 'NNS', 'O'),\n",
      " ('dumped', 'VBD', 'O'),\n",
      " ('riskier', 'JJR', 'O'),\n",
      " ('assets', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('MSCI', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('broadest', 'JJS', 'O'),\n",
      " ('index', 'NN', 'B-NP'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Asia-Pacific', 'NNP', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('outside', 'IN', 'O'),\n",
      " ('Japan', 'NNP', 'O'),\n",
      " ('dropped', 'VBD', 'O'),\n",
      " ('1.7', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('1-1/2', 'JJ', 'I-NP'),\n",
      " ('week', 'NN', 'I-NP'),\n",
      " ('trough', 'NN', 'B-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('with', 'IN', 'O'),\n",
      " ('Australian', 'JJ', 'O'),\n",
      " ('shares', 'NNS', 'O'),\n",
      " ('sinking', 'VBG', 'O'),\n",
      " ('1.6', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('.', '.', 'O'),\n",
      " ('Japan', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('Nikkei', 'NNP', 'O'),\n",
      " ('dived', 'VBD', 'O'),\n",
      " ('3.1', 'CD', 'O'),\n",
      " ('percent', 'NN', 'B-NP'),\n",
      " ('led', 'VBN', 'O'),\n",
      " ('by', 'IN', 'O'),\n",
      " ('losses', 'NNS', 'O'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('electric', 'JJ', 'B-NP'),\n",
      " ('machinery', 'NN', 'I-NP'),\n",
      " ('makers', 'NNS', 'O'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('suppliers', 'NNS', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('Apple', 'NNP', 'O'),\n",
      " ('’', 'NNP', 'O'),\n",
      " ('s', 'VBD', 'O'),\n",
      " ('iphone', 'NN', 'B-NP'),\n",
      " ('parts', 'NNS', 'O'),\n",
      " ('.', '.', 'O'),\n",
      " ('Sterling', 'NN', 'B-NP'),\n",
      " ('fell', 'VBD', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('$', '$', 'O'),\n",
      " ('1.286', 'CD', 'O'),\n",
      " ('after', 'IN', 'O'),\n",
      " ('three', 'CD', 'O'),\n",
      " ('straight', 'JJ', 'O'),\n",
      " ('sessions', 'NNS', 'O'),\n",
      " ('of', 'IN', 'O'),\n",
      " ('losses', 'NNS', 'O'),\n",
      " ('took', 'VBD', 'O'),\n",
      " ('it', 'PRP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('lowest', 'JJS', 'O'),\n",
      " ('since', 'IN', 'O'),\n",
      " ('Nov.1', 'NNP', 'O'),\n",
      " ('as', 'IN', 'O'),\n",
      " ('there', 'EX', 'O'),\n",
      " ('were', 'VBD', 'O'),\n",
      " ('still', 'RB', 'O'),\n",
      " ('considerable', 'JJ', 'O'),\n",
      " ('unresolved', 'JJ', 'O'),\n",
      " ('issues', 'NNS', 'O'),\n",
      " ('with', 'IN', 'O'),\n",
      " ('the', 'DT', 'O'),\n",
      " ('European', 'NNP', 'O'),\n",
      " ('Union', 'NNP', 'O'),\n",
      " ('over', 'IN', 'O'),\n",
      " ('Brexit', 'NNP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('British', 'NNP', 'O'),\n",
      " ('Prime', 'NNP', 'O'),\n",
      " ('Minister', 'NNP', 'O'),\n",
      " ('Theresa', 'NNP', 'O'),\n",
      " ('May', 'NNP', 'O'),\n",
      " ('said', 'VBD', 'O'),\n",
      " ('on', 'IN', 'O'),\n",
      " ('Monday', 'NNP', 'O'),\n",
      " ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "article = '''\n",
    "Asian shares skidded on Tuesday after a rout in tech stocks put Wall Street to the sword, while a \n",
    "sharp drop in oil prices and political risks in Europe pushed the dollar to 16-month highs as investors dumped \n",
    "riskier assets. MSCI’s broadest index of Asia-Pacific shares outside Japan dropped 1.7 percent to a 1-1/2 \n",
    "week trough, with Australian shares sinking 1.6 percent. Japan’s Nikkei dived 3.1 percent led by losses in \n",
    "electric machinery makers and suppliers of Apple’s iphone parts. Sterling fell to $1.286 after three straight \n",
    "sessions of losses took it to the lowest since Nov.1 as there were still considerable unresolved issues with the\n",
    "European Union over Brexit, British Prime Minister Theresa May said on Monday.'''\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "\n",
    "print('NTLK version: %s' % (nltk.__version__))\n",
    "\n",
    "def fn_preprocess(art):\n",
    "    art = nltk.word_tokenize(art)\n",
    "    art = nltk.pos_tag(art)\n",
    "    return art\n",
    "\n",
    "art_processed = fn_preprocess(article)\n",
    "\n",
    "results = ne_chunk(art_processed)\n",
    "\n",
    "for x in str(results).split('\\n'):\n",
    "    if '/NN' in x:\n",
    "        print(x)\n",
    "        \n",
    "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(art_processed)\n",
    "print(cs)\n",
    "\n",
    "iob_tagged = tree2conlltags(cs)\n",
    "pprint(iob_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
